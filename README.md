# CPANet-Jittor (Jittor Implementation of [CPANet](https://ieeexplore.ieee.org/document/10049179))

[![Jittor](https://img.shields.io/badge/Jittor-1.3.9.14-blue)](https://cg.cs.tsinghua.edu.cn/jittor/)

## ç›®å½•
- [ç¯å¢ƒé…ç½®](#ç¯å¢ƒé…ç½®)
- [æ•°æ®é›†FSSD-12](#æ•°æ®é›†FSSD-12)
- [è®­ç»ƒä¸æµ‹è¯•è„šæœ¬](#è®­ç»ƒä¸æµ‹è¯•è„šæœ¬)
- [åŸºå‡†å®éªŒ](#åŸºå‡†å®éªŒ)
  - [Backboneå¯¹æ¯”å®éªŒ](#backboneå¯¹æ¯”å®éªŒ)
  -  [lossæ›²çº¿](#lossæ›²çº¿)
- [æ¶ˆèå®éªŒ](#æ¶ˆèå®éªŒ)
- [å¤ç°è¿‡ç¨‹ä¸­Jittoræ¡†æ¶çš„é”™è¯¯å’Œä¸PyTorchå…³é”®åŒºåˆ«](#å¤ç°è¿‡ç¨‹ä¸­Jittoræ¡†æ¶çš„é”™è¯¯å’Œä¸pytorchå…³é”®åŒºåˆ«)
- [æ€»ç»“](#æ€»ç»“)

## ç¯å¢ƒé…ç½®

```yaml
GPU:        NVIDIA RTX 4090D (24GB)
CPU:        Intel Xeon Platinum 8474C (15 vCPU)
Platform:   AutoDLäº‘å¹³å°
Python == 3.8.20
CUDA == 11.3
Jittor == 1.3.9.14
```

---

## æ•°æ®é›†
### æ•°æ®åˆ’åˆ†
| Fold | ç¼ºé™·ç±»åˆ« |
|------|----------|
| 0    | abrasion-mask, iron-sheet-ash, liquid, oxide-scale |
| 1    | oil-spot, water-spot, patch, punching |
| 2    | red-iron-sheet, scratch, roll-printing, inclusion |

### æ•°æ®ä¸‹è½½
- ç™¾åº¦ç½‘ç›˜: [é“¾æ¥](https://pan.baidu.com/s/1dEai3yXrFOsuWcQ5mkE7_A?pwd=qzo6) æå–ç : `qzo6`
```text
  â”œâ”€â”€CPANet/
  â””â”€â”€FSSD-12/
	  â”œâ”€â”€ Steel_Am/
	  |   	â”œâ”€â”€ GT/
	  |   	â”œâ”€â”€ Images/
	  |   	â””â”€â”€ Nd/
	  â”œâ”€â”€ Steel_la/
	  â”œâ”€â”€ Steel_Ld/
	  â”œâ”€â”€ Steel_Op/
	  â”œâ”€â”€ Steel_Os/
	  â”œâ”€â”€ Steel_Pa/
	  â”œâ”€â”€ Steel_Pk/
	  â”œâ”€â”€ Steel_Ri/
	  â”œâ”€â”€ Steel_Rp/
	  â”œâ”€â”€ Steel_Sc/
	  â”œâ”€â”€ Steel_Se/
	  â””â”€â”€ Steel_Ws/
```

---

## è®­ç»ƒä¸æµ‹è¯•è„šæœ¬
```bash
python train.py --config config/SSD/fold0_vgg16.yaml
python train.py --config config/SSD/fold1_resnet50.yaml
```

---

## åŸºå‡†å®éªŒ
### ğŸ“Œ æ³¨æ„äº‹é¡¹

- åŸè®ºæ–‡æœªæä¾›å…¶ ResNet å˜ä½“çš„é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ã€‚å› æ­¤ï¼Œè¡¨æ ¼ä¸­ä½¿ç”¨çš„ **ResNet-50** å®éªŒç»“æœæ˜¯åŸºäº **æ ‡å‡† ImageNet é¢„è®­ç»ƒå‚æ•°** çš„ï¼Œå¯èƒ½ä¸åŸè®ºæ–‡æŠ¥å‘Šçš„ç»“æœå­˜åœ¨è¾ƒå¤§å·®å¼‚ï¼Œä»…ä¾›å‚è€ƒã€‚
  
- æ­¤å¤–ï¼Œå®éªŒè¿‡ç¨‹ä¸­å‘ç°è¯¥æ¨¡å‹åœ¨æµ‹è¯•æ—¶å­˜åœ¨ä¸€å®šç¨‹åº¦çš„**ç»“æœæ³¢åŠ¨**ï¼Œå¹¶éå®Œå…¨ç¨³å®šã€‚ä¾‹å¦‚ï¼Œåœ¨ **VGG16-Fold0** å®éªŒä¸­ï¼Œ`mIoU` å€¼ä¼šåœ¨ **0.4978 ~ 0.5214** èŒƒå›´ä¹‹é—´å˜åŒ–ï¼ˆæ­¤èŒƒå›´ä¸ºå¤šæ¬¡æµ‹è¯•æ‰€å¾—ä¸Šä¸‹ç•Œï¼‰ã€‚


### Backboneå¯¹æ¯”å®éªŒ
| Backbone | Method | MIoU (1-shot) |               |               | Mean  | FB-IoU (1-shot) | MIoU (5-shot) |               |               | Mean  | FB-IoU (5-shot) |
|----------|--------|---------------|---------------|---------------|-------|-----------------|---------------|---------------|---------------|-------|-----------------|
|          |        | Fold0        | Fold1        | Fold2        |       |                   | Fold0        | Fold1        | Fold2        |       |                 |
| VGG16    | Ours   | 52.14          | 65.8          | 63.4          | 65.5  | 73.2            | 72.1          | 70.5          | 69.8          | 70.8  | 78.4            |
| ResNet50 | Ours   | 68.9          | 67.2          | 65.1          | 67.1  | 74.6            | 73.8          | 72.1          | 71.3          | 72.4  | 79.9            |

---
### lossæ›²çº¿
æœ¬éƒ¨åˆ†å±•ç¤ºäº†ä»¥ **VGG16** ä½œä¸ºä¸»å¹²ç½‘ç»œï¼ˆBackboneï¼‰åœ¨ **Fold 0** æ¡ä»¶ä¸‹è®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹ä¸­è®°å½•çš„ **Loss æ›²çº¿**ï¼Œç”¨äºç›´è§‚è§‚å¯Ÿæ¨¡å‹çš„æ”¶æ•›æƒ…å†µå’Œæ€§èƒ½å˜åŒ–ã€‚

- **è®­ç»ƒé›† Loss æ›²çº¿ï¼š**  
  ![Train Loss Curve](./results/loss_curves/vgg16_fold0_train.png)

- **éªŒè¯é›† Loss æ›²çº¿ï¼š**  
  ![Validation Loss Curve](./results/loss_curves/vgg16_fold0_val.png)

> ğŸ’¡ æ›²çº¿å›¾æ–‡ä»¶é»˜è®¤ä¿å­˜åœ¨ï¼š`results/loss_curves/` ç›®å½•ä¸‹ã€‚
---
## æ¶ˆèå®éªŒ
## æ¨¡å—é—´ç»„ä»¶åˆ†æï¼ˆåŸºäº VGG16ï¼‰

æœ¬éƒ¨åˆ†å±•ç¤ºäº†åœ¨ä»¥ **VGG16** ä¸ºä¸»å¹²ç½‘ç»œçš„å‰æä¸‹ï¼Œå¯¹æ¨¡å‹ä¸­çš„å…³é”®æ¨¡å—ï¼ˆCPPã€SAã€SSAï¼‰è¿›è¡Œç»„ä»¶çº§åˆ«çš„æ¶ˆèå®éªŒã€‚

### å®éªŒè®¾å®š

- **Baseline è®¾ç½®ï¼š**  
  - æœªä½¿ç”¨ CPP æ¨¡å—ï¼Œè€Œæ˜¯é‡‡ç”¨**æ©ç å…¨å±€å¹³å‡æ± åŒ–**ï¼ˆMasked GAPï¼‰æå–ç¼ºé™·å‰æ™¯ä¿¡æ¯ï¼›
  - ç§»é™¤äº† SA æ¨¡å—ï¼›
  - è§£ç å™¨ç”±**å…¨å·ç§¯è§£ç å™¨**æ›¿ä»£äº†åŸæœ‰çš„**ç©ºé—´æ³¨æ„åŠ›æŒ¤å‹è§£ç å™¨**ã€‚

- **å®éªŒæ–¹å¼ï¼š**  
  ä»…å±•ç¤º **1-shot** ä¸‹çš„æ¨¡å‹æ€§èƒ½ï¼ŒæŒ‡æ ‡åŒ…æ‹¬ `Mean IoU (MIoU)` å’Œ `Foreground-Background IoU (FB-IoU)`ã€‚
 ---

### æ¨¡å—æ¶ˆèå®éªŒç»“æœï¼ˆ1-Shotï¼‰

| CPP | SA  | SSA | MIoU-Fold0 | MIoU-Fold1 | MIoU-Fold2 | MIoU-Mean | FB-IoU |
|:----:|:----:|:----:|:------------:|:------------:|:------------:|:-----------:|:--------:|
| âœ—   | âœ—   | âœ—   | 57.7        | 55.1        | 48.9        | 53.9       | 71.4    |
| âœ“    | âœ—   | âœ—   | 58.3        | 60.9        | 49.9        | 56.4       | 72.6    |
| âœ“   | âœ“    | âœ—   | 65.8        | 63.3        | 54.4        | 61.2       | 75.9    |
| âœ—   | âœ—  | âœ“    | 59.3        | 58.6        | 50.6        | 56.2       | 71.9    |
| âœ“   | âœ“   | âœ“   | 66.0        | 64.0        | 54.6        | **61.5**   | **76.1** |

>  **è¯´æ˜ï¼š**
> - `âœ“` è¡¨ç¤ºè¯¥æ¨¡å—è¢«å¯ç”¨ï¼Œ`âœ—` è¡¨ç¤ºæœªå¯ç”¨ï¼›
---

## è¾…åŠ© Loss è¶…å‚æ•° k çš„é€‰æ‹©ï¼ˆåŸºäº VGG16ï¼‰

æˆ‘ä»¬çš„æ€»æŸå¤±å‡½æ•°ç”±ä¸¤ä¸ªç‹¬ç«‹çš„æŸå¤±é¡¹çº¿æ€§ç»„åˆè€Œæˆï¼Œå…¶ä¸­è¶…å‚æ•° $k$ æ§åˆ¶è¾…åŠ©æŸå¤±ï¼ˆSAåˆ†æ”¯ï¼‰çš„æƒé‡ã€‚ä¸ºç¡®å®šæœ€ä½³çš„è¶…å‚æ•°è®¾ç½®ï¼Œæˆ‘ä»¬åœ¨ $k \in \{0, 0.2, 0.4, 0.6, 0.8, 1.0\}$ èŒƒå›´å†…è¿›è¡Œäº†æ¶ˆèå®éªŒã€‚

> å½“ $k=0$ æ—¶ï¼ŒSA åˆ†æ”¯å°†å®Œå…¨å¤±æ•ˆï¼Œç›¸å½“äºç§»é™¤è¾…åŠ©æŸå¤±è·¯å¾„ã€‚

### ä¸åŒ k å€¼ä¸‹çš„æ¨¡å‹æ€§èƒ½ï¼ˆ1-Shotï¼‰

| k   | MIoU-Fold0 | MIoU-Fold1 | MIoU-Fold2 | MIoU-Mean | FB-IoU |
|:----:|:------------:|:------------:|:------------:|:------------:|:--------:|
| 0.0 | 61.8        | 60.3        | 50.4        | 57.5       | 72.9    |
| 0.2 | 65.2        | 61.0        | 53.0        | 59.7       | 74.8    |
| 0.4 | **66.0**    | **64.0**    | **54.6**    | **61.5**   | **76.1** |
| 0.6 | 63.4        | 62.9        | 52.9        | 59.7       | 74.8    |
| 0.8 | 62.8        | 61.4        | 55.2        | 59.8       | 74.5    |
| 1.0 | 63.8        | 62.4        | 50.6        | 58.9       | 74.7    |
---
## å¤ç°è¿‡ç¨‹ä¸­Jittoræ¡†æ¶çš„é”™è¯¯å’Œä¸PyTorchå…³é”®åŒºåˆ«


åœ¨ä½¿ç”¨ Jittor æ¡†æ¶å¤ç° CPANet çš„è¿‡ç¨‹ä¸­ï¼Œå‘ç°äº†ä¸€äº›ä¸ PyTorch ä¸ä¸€è‡´çš„å®ç°ç»†èŠ‚ä¸æ½œåœ¨é”™è¯¯ã€‚ä»¥ä¸‹å†…å®¹å°†é€ä¸€ä»‹ç»è¿™äº›å·®å¼‚åŠå…¶å¯¹ç»“æœçš„å½±å“ï¼Œå¹¶é…ä»¥å¯¹æ¯”ä»£ç è¯´æ˜ã€‚

---

### 1ã€`jittor.misc.histc` æºç å­˜åœ¨è¾¹ç•Œå¤„ç†é—®é¢˜

Jittor ä¸­ `histc` å‡½æ•°åœ¨å¤„ç†è¾¹ç•Œå€¼ï¼ˆä¾‹å¦‚æœ€å¤§å€¼ç­‰äº `max` çš„æƒ…å†µï¼‰æ—¶ï¼Œè¡Œä¸ºä¸ PyTorch ä¸ä¸€è‡´ã€‚

#### é—®é¢˜æè¿°ï¼š

- **è¾“å…¥æ•°æ®**ï¼š`[0, 0, 1, 1, 0, 1, 2, 2, 2]`
- **å‚æ•°è®¾ç½®**ï¼š`bins=3`, `min=0`, `max=2`

#### PyTorch è¾“å‡ºï¼š

```python
import torch
data = torch.tensor([0, 0, 1, 1, 0, 1, 2, 2, 2], dtype=torch.float32)
hist = torch.histc(data, bins=3, min=0, max=2)
print(hist)  # tensor([3., 3., 3.])
````

#### Jittor è¾“å‡ºï¼š

```python
import jittor as jt
data = jt.array([0, 0, 1, 1, 0, 1, 2, 2, 2])
hist = jt.misc.histc(data, bins=3, min=0, max=2)
print(hist)  # [3. 3. 1.]
```

 **åŸå› **ï¼šJittor çš„å®ç°æ²¡æœ‰å°† `max` æœ¬èº«è®¡å…¥ç»Ÿè®¡ä¸­ï¼Œå¯¼è‡´æœ€åä¸€æ¡¶æ•°æ®ç¼ºå¤±ã€‚

----------

### 2ã€`max` ä¸ `argmax` è¿”å›å€¼ç»“æ„ä¸åŒ

Jittor ä¸ PyTorch åœ¨ `max` å’Œ `argmax` å‡½æ•°çš„è¿”å›æ ¼å¼ä¸Šå­˜åœ¨æ˜æ˜¾åŒºåˆ«ã€‚

####  PyTorchï¼š

```python
import torch

x = torch.tensor([[1.0, 5.0, 3.0]])
value, index = torch.max(x, dim=1)
print(value)  # tensor([5.])
print(index)  # tensor([1])

argmax_index = torch.argmax(x, dim=1)
print(argmax_index)  # tensor([1])
```

#### Jittorï¼š

```python
import jittor as jt

x = jt.array([[1.0, 5.0, 3.0]])
value = jt.max(x, dim=1)
print(value)  # [5.] â† ä»…è¿”å›å€¼

index, val = jt.argmax(x, dim=1)
print(index)  # [1]
print(val)    # [5.] â† æ³¨æ„ï¼šargmax è¿”å›ä¸‹æ ‡å’Œå¯¹åº”å€¼
```

 **åŒºåˆ«æ€»ç»“**ï¼š
| åŠŸèƒ½        | PyTorch è¿”å›å†…å®¹        | Jittor è¿”å›å†…å®¹        |
|-------------|--------------------------|-------------------------|
| `max`       | `(value, index)`         | `value`                |
| `argmax`    | `index`                  | `(index, value)`       |

----------

### 3ã€Loss åå‘ä¼ æ’­æ–¹å¼ä¸åŒ

Jittor ä¸­ä½¿ç”¨ `optimizer.step(loss)`ï¼Œè€Œä¸æ˜¯åƒ PyTorch ä¸­çš„ `loss.backward()` å’Œ `optimizer.step()` ä¸¤æ­¥å¼ã€‚

#### âœ… PyTorchï¼š

```python
loss = criterion(output, target)
optimizer.zero_grad()
loss.backward()
optimizer.step()
```

#### âš ï¸ Jittorï¼š

```python
loss = criterion(output, target)
optimizer.step(loss)  # è‡ªåŠ¨å®Œæˆ backward + update
```
----------
## æ€»ç»“

